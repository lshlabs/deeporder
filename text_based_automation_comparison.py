"""
ğŸ¯ í…ìŠ¤íŠ¸ ê¸°ë°˜ UI ìë™í™” ê¸°ìˆ  ì¢…í•© ë¹„êµ
OpenCV í…œí”Œë¦¿ ë§¤ì¹­ vs ë‹¤ì–‘í•œ OCR ê¸°ìˆ ë“¤

ë°°ë‹¬ì•± "ì ‘ìˆ˜", "ê±°ë¶€" ë²„íŠ¼ ê°™ì€ í…ìŠ¤íŠ¸ UIì— ìµœì í™”ëœ ì†”ë£¨ì…˜ë“¤
"""

import cv2
import numpy as np
import time
import mss
from typing import List, Tuple, Dict, Optional
import json

# OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import easyocr
    HAS_EASYOCR = True
except ImportError:
    HAS_EASYOCR = False

try:
    import pytesseract
    HAS_TESSERACT = True
except ImportError:
    HAS_TESSERACT = False

try:
    import paddleocr
    HAS_PADDLEOCR = True
except ImportError:
    HAS_PADDLEOCR = False

class TextBasedUIAutomation:
    """
    ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ì¸ì‹ ê¸°ìˆ ë“¤ì„ ë¹„êµí•˜ê³  ìµœì ì˜ ì†”ë£¨ì…˜ ì œê³µ
    """
    
    def __init__(self):
        self.ocr_engines = {}
        self.performance_stats = {
            'opencv_template': {'times': [], 'accuracies': []},
            'easyocr': {'times': [], 'accuracies': []},
            'tesseract': {'times': [], 'accuracies': []},
            'paddleocr': {'times': [], 'accuracies': []},
            'hybrid': {'times': [], 'accuracies': []}
        }
        
        self._initialize_ocr_engines()
        
    def _initialize_ocr_engines(self):
        """OCR ì—”ì§„ë“¤ ì´ˆê¸°í™”"""
        
        # EasyOCR (í•œê¸€+ì˜ì–´, GPU/CPU ìë™ ì„ íƒ)
        if HAS_EASYOCR:
            print("ğŸ”„ EasyOCR ì´ˆê¸°í™” ì¤‘...")
            self.ocr_engines['easyocr'] = easyocr.Reader(['ko', 'en'], gpu=False)
            print("âœ… EasyOCR ì¤€ë¹„ ì™„ë£Œ")
        
        # Tesseract (Googleì˜ ì˜¤í”ˆì†ŒìŠ¤ OCR)
        if HAS_TESSERACT:
            try:
                # Tesseract ê²½ë¡œ í™•ì¸
                pytesseract.get_tesseract_version()
                self.ocr_engines['tesseract'] = True
                print("âœ… Tesseract ì¤€ë¹„ ì™„ë£Œ")
            except:
                print("âŒ Tesseract ì„¤ì¹˜ í•„ìš”: brew install tesseract tesseract-lang")
        
        # PaddleOCR (ì¤‘êµ­ ë°”ì´ë‘ì˜ ê³ ì„±ëŠ¥ OCR)
        if HAS_PADDLEOCR:
            print("ğŸ”„ PaddleOCR ì´ˆê¸°í™” ì¤‘...")
            self.ocr_engines['paddleocr'] = paddleocr.PaddleOCR(use_angle_cls=True, lang='korean')
            print("âœ… PaddleOCR ì¤€ë¹„ ì™„ë£Œ")

    def capture_screen(self) -> np.ndarray:
        """í™”ë©´ ìº¡ì²˜"""
        with mss.mss() as sct:
            # í…ŒìŠ¤íŠ¸ìš© ì‘ì€ ì˜ì—­ ìº¡ì²˜
            monitor = {"top": 200, "left": 200, "width": 1000, "height": 600}
            screenshot = sct.grab(monitor)
            return np.array(screenshot)[:, :, :3]  # RGB

# =============================================================================
# 1. OpenCV í…œí”Œë¦¿ ë§¤ì¹­ (ê¸°ì¡´ ë°©ì‹)
# =============================================================================

class OpenCVTemplateMatcher:
    """ê¸°ì¡´ OpenCV í…œí”Œë¦¿ ë§¤ì¹­ ë°©ì‹"""
    
    def __init__(self, threshold=0.7):
        self.threshold = threshold
        self.template_cache = {}
    
    def find_button_by_template(self, screenshot: np.ndarray, button_type: str) -> Tuple[bool, Optional[Tuple], float]:
        """
        í…œí”Œë¦¿ ë§¤ì¹­ìœ¼ë¡œ ë²„íŠ¼ ì°¾ê¸°
        
        Args:
            screenshot: ìŠ¤í¬ë¦°ìƒ·
            button_type: 'accept' ë˜ëŠ” 'reject'
        """
        start_time = time.time()
        
        try:
            # ì‹¤ì œë¡œëŠ” ì €ì¥ëœ í…œí”Œë¦¿ ì´ë¯¸ì§€ ì‚¬ìš©
            # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
            gray_screen = cv2.cvtColor(screenshot, cv2.COLOR_RGB2GRAY)
            
            # ê°€ìƒì˜ í…œí”Œë¦¿ (ì‹¤ì œë¡œëŠ” íŒŒì¼ì—ì„œ ë¡œë“œ)
            h, w = gray_screen.shape
            if button_type == 'accept':
                template = gray_screen[h//2-50:h//2+50, w//2-100:w//2]  # ì ‘ìˆ˜ ë²„íŠ¼ ìœ„ì¹˜ ì¶”ì •
            else:
                template = gray_screen[h//2-50:h//2+50, w//2:w//2+100]  # ê±°ë¶€ ë²„íŠ¼ ìœ„ì¹˜ ì¶”ì •
            
            if template.size == 0:
                return False, None, 0.0
            
            result = cv2.matchTemplate(gray_screen, template, cv2.TM_CCOEFF_NORMED)
            _, max_val, _, max_loc = cv2.minMaxLoc(result)
            
            processing_time = time.time() - start_time
            
            if max_val > self.threshold:
                center_x = max_loc[0] + template.shape[1] // 2
                center_y = max_loc[1] + template.shape[0] // 2
                return True, (center_x, center_y), processing_time
            else:
                return False, None, processing_time
                
        except Exception as e:
            processing_time = time.time() - start_time
            return False, None, processing_time

# =============================================================================
# 2. EasyOCR (ê°€ì¥ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ OCR)
# =============================================================================

class EasyOCRDetector:
    """
    EasyOCR ê¸°ë°˜ í…ìŠ¤íŠ¸ ë²„íŠ¼ ê°ì§€
    
    âœ… ì¥ì :
    - ì„¤ì¹˜ ì‰¬ì›€: pip install easyocr
    - í•œê¸€ ì§€ì› ìš°ìˆ˜
    - GPU ìë™ í™œìš©
    - ë†’ì€ ì •í™•ë„
    
    âŒ ë‹¨ì :
    - ì´ˆê¸° ë¡œë”© ì‹œê°„ (2-3ì´ˆ)
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ
    """
    
    def __init__(self):
        if HAS_EASYOCR:
            self.reader = easyocr.Reader(['ko', 'en'], gpu=False)
        else:
            self.reader = None
    
    def find_button_by_text(self, screenshot: np.ndarray, target_text: str) -> Tuple[bool, Optional[Tuple], float]:
        """
        í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë²„íŠ¼ ì°¾ê¸°
        
        Args:
            screenshot: ìŠ¤í¬ë¦°ìƒ·
            target_text: ì°¾ì„ í…ìŠ¤íŠ¸ ("ì ‘ìˆ˜", "ê±°ë¶€" ë“±)
        """
        if not self.reader:
            return False, None, 9999
        
        start_time = time.time()
        
        try:
            # OCR ì‹¤í–‰
            results = self.reader.readtext(screenshot, paragraph=False)
            
            for (bbox, text, confidence) in results:
                # í…ìŠ¤íŠ¸ ë§¤ì¹­ (ìœ ì‚¬ë„ ê¸°ë°˜)
                similarity = self._calculate_similarity(target_text, text)
                
                if similarity > 0.7 and confidence > 0.6:
                    # ì¤‘ì‹¬ì  ê³„ì‚°
                    center_x = int((bbox[0][0] + bbox[2][0]) / 2)
                    center_y = int((bbox[0][1] + bbox[2][1]) / 2)
                    
                    processing_time = time.time() - start_time
                    return True, (center_x, center_y), processing_time
            
            processing_time = time.time() - start_time
            return False, None, processing_time
            
        except Exception as e:
            processing_time = time.time() - start_time
            return False, None, processing_time
    
    def _calculate_similarity(self, target: str, found: str) -> float:
        """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        from difflib import SequenceMatcher
        return SequenceMatcher(None, target.lower(), found.lower()).ratio()

# =============================================================================
# 3. Tesseract (Googleì˜ ì „í†µì  OCR)
# =============================================================================

class TesseractDetector:
    """
    Tesseract ê¸°ë°˜ í…ìŠ¤íŠ¸ ê°ì§€
    
    âœ… ì¥ì :
    - ë§¤ìš° ë¹ ë¦„
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ìŒ
    - ì•ˆì •ì 
    - ì˜¤í”ˆì†ŒìŠ¤
    
    âŒ ë‹¨ì :
    - í•œê¸€ ì¸ì‹ë¥  ë‚®ìŒ
    - ì„¤ì • ë³µì¡
    - ë…¸ì´ì¦ˆì— ë¯¼ê°
    """
    
    def __init__(self):
        self.available = HAS_TESSERACT
        
    def find_button_by_text(self, screenshot: np.ndarray, target_text: str) -> Tuple[bool, Optional[Tuple], float]:
        """Tesseractë¡œ ë²„íŠ¼ ì°¾ê¸°"""
        if not self.available:
            return False, None, 9999
            
        start_time = time.time()
        
        try:
            # ì „ì²˜ë¦¬ (TesseractëŠ” ì „ì²˜ë¦¬ê°€ ì¤‘ìš”)
            gray = cv2.cvtColor(screenshot, cv2.COLOR_RGB2GRAY)
            
            # ì´ì§„í™”ë¡œ í…ìŠ¤íŠ¸ ì„ ëª…í•˜ê²Œ
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # í•œê¸€+ì˜ì–´ ì„¤ì •
            config = '--oem 3 --psm 6 -l kor+eng'
            
            # OCR ì‹¤í–‰ (ìœ„ì¹˜ ì •ë³´ í¬í•¨)
            data = pytesseract.image_to_data(binary, config=config, output_type=pytesseract.Output.DICT)
            
            # ê²°ê³¼ ë¶„ì„
            for i, text in enumerate(data['text']):
                if text.strip() and target_text in text:
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´
                    x = data['left'][i]
                    y = data['top'][i]
                    w = data['width'][i]
                    h = data['height'][i]
                    conf = int(data['conf'][i])
                    
                    if conf > 50:  # ì‹ ë¢°ë„ 50% ì´ìƒ
                        center_x = x + w // 2
                        center_y = y + h // 2
                        
                        processing_time = time.time() - start_time
                        return True, (center_x, center_y), processing_time
            
            processing_time = time.time() - start_time
            return False, None, processing_time
            
        except Exception as e:
            processing_time = time.time() - start_time
            return False, None, processing_time

# =============================================================================
# 4. PaddleOCR (ë°”ì´ë‘ì˜ ê³ ì„±ëŠ¥ OCR)
# =============================================================================

class PaddleOCRDetector:
    """
    PaddleOCR ê¸°ë°˜ ê°ì§€
    
    âœ… ì¥ì :
    - ë§¤ìš° ë†’ì€ ì •í™•ë„
    - ë‹¤ì–‘í•œ ì–¸ì–´ ì§€ì›
    - íšŒì „ëœ í…ìŠ¤íŠ¸ë„ ì¸ì‹
    - ìƒì—…ì  ì‚¬ìš© ê°€ëŠ¥
    
    âŒ ë‹¨ì :
    - í° ìš©ëŸ‰ (ìˆ˜ë°± MB)
    - ì´ˆê¸° ë¡œë”© ëŠë¦¼
    - ì¤‘êµ­ì–´ ìœ„ì£¼ ìµœì í™”
    """
    
    def __init__(self):
        self.available = HAS_PADDLEOCR
        if self.available:
            self.ocr = paddleocr.PaddleOCR(use_angle_cls=True, lang='korean')
    
    def find_button_by_text(self, screenshot: np.ndarray, target_text: str) -> Tuple[bool, Optional[Tuple], float]:
        """PaddleOCRë¡œ ë²„íŠ¼ ì°¾ê¸°"""
        if not self.available:
            return False, None, 9999
            
        start_time = time.time()
        
        try:
            results = self.ocr.ocr(screenshot, cls=True)
            
            if results and results[0]:
                for line in results[0]:
                    bbox, (text, confidence) = line
                    
                    if target_text in text and confidence > 0.7:
                        # ì¤‘ì‹¬ì  ê³„ì‚°
                        center_x = int((bbox[0][0] + bbox[2][0]) / 2)
                        center_y = int((bbox[0][1] + bbox[2][1]) / 2)
                        
                        processing_time = time.time() - start_time
                        return True, (center_x, center_y), processing_time
            
            processing_time = time.time() - start_time
            return False, None, processing_time
            
        except Exception as e:
            processing_time = time.time() - start_time
            return False, None, processing_time

# =============================================================================
# 5. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²• (ìµœê³  ì„±ëŠ¥)
# =============================================================================

class HybridTextDetector:
    """
    ì—¬ëŸ¬ OCR ê¸°ìˆ ì„ ì¡°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•
    
    ğŸ¯ ì „ëµ:
    1. ë¹ ë¥¸ Tesseractë¡œ 1ì°¨ ìŠ¤í¬ë¦¬ë‹
    2. ì‹¤íŒ¨ ì‹œ EasyOCRë¡œ ì •ë°€ ë¶„ì„
    3. ìƒ‰ìƒ í•„í„°ë§ìœ¼ë¡œ í›„ë³´ ì˜ì—­ ì¶•ì†Œ
    """
    
    def __init__(self):
        self.tesseract = TesseractDetector()
        self.easyocr = EasyOCRDetector()
        self.color_filters = {
            'accept': ([100, 50, 50], [130, 255, 255]),  # íŒŒë€ìƒ‰ ê³„ì—´
            'reject': ([0, 50, 50], [20, 255, 255])      # ë¹¨ê°„ìƒ‰ ê³„ì—´
        }
    
    def find_button_smart(self, screenshot: np.ndarray, target_text: str, button_type: str = 'accept') -> Tuple[bool, Optional[Tuple], float, str]:
        """
        ìŠ¤ë§ˆíŠ¸ í•˜ì´ë¸Œë¦¬ë“œ ë²„íŠ¼ ì°¾ê¸°
        
        Returns:
            (found, location, processing_time, method_used)
        """
        start_time = time.time()
        
        # 1ë‹¨ê³„: ìƒ‰ìƒìœ¼ë¡œ í›„ë³´ ì˜ì—­ ì¢íˆê¸°
        roi_candidates = self._find_color_regions(screenshot, button_type)
        
        if roi_candidates:
            # ROI ì˜ì—­ì—ì„œë§Œ OCR ì‹¤í–‰ (í›¨ì”¬ ë¹ ë¦„)
            for roi in roi_candidates[:3]:  # ìƒìœ„ 3ê°œ í›„ë³´ë§Œ
                roi_img = self._extract_roi(screenshot, roi)
                
                # 2ë‹¨ê³„: ë¹ ë¥¸ Tesseract ì‹œë„
                found, location, _ = self.tesseract.find_button_by_text(roi_img, target_text)
                if found:
                    # ROI ì¢Œí‘œë¥¼ ì „ì²´ í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜
                    global_location = (location[0] + roi['x'], location[1] + roi['y'])
                    processing_time = time.time() - start_time
                    return True, global_location, processing_time, 'Tesseract+Color'
                
                # 3ë‹¨ê³„: EasyOCRë¡œ ì •ë°€ ë¶„ì„
                found, location, _ = self.easyocr.find_button_by_text(roi_img, target_text)
                if found:
                    global_location = (location[0] + roi['x'], location[1] + roi['y'])
                    processing_time = time.time() - start_time
                    return True, global_location, processing_time, 'EasyOCR+Color'
        
        # 4ë‹¨ê³„: ì „ì²´ í™”ë©´ì—ì„œ EasyOCR (ìµœí›„ ìˆ˜ë‹¨)
        found, location, _ = self.easyocr.find_button_by_text(screenshot, target_text)
        processing_time = time.time() - start_time
        
        if found:
            return True, location, processing_time, 'EasyOCR_Fullscreen'
        else:
            return False, None, processing_time, 'Failed'
    
    def _find_color_regions(self, screenshot: np.ndarray, button_type: str) -> List[Dict]:
        """ìƒ‰ìƒ ê¸°ë°˜ìœ¼ë¡œ ë²„íŠ¼ í›„ë³´ ì˜ì—­ ì°¾ê¸°"""
        try:
            hsv = cv2.cvtColor(screenshot, cv2.COLOR_RGB2HSV)
            
            if button_type in self.color_filters:
                lower, upper = self.color_filters[button_type]
                mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
                
                # ë…¸ì´ì¦ˆ ì œê±°
                kernel = np.ones((5, 5), np.uint8)
                mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
                
                # ìœ¤ê³½ì„  ì°¾ê¸°
                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                regions = []
                for contour in contours:
                    area = cv2.contourArea(contour)
                    if 500 < area < 50000:  # ë²„íŠ¼ í¬ê¸° ë²”ìœ„
                        x, y, w, h = cv2.boundingRect(contour)
                        regions.append({'x': x, 'y': y, 'w': w, 'h': h, 'area': area})
                
                # ë©´ì  ìˆœìœ¼ë¡œ ì •ë ¬ (í° ê²ƒë¶€í„°)
                regions.sort(key=lambda r: r['area'], reverse=True)
                return regions
                
        except Exception:
            pass
            
        return []
    
    def _extract_roi(self, screenshot: np.ndarray, roi: Dict) -> np.ndarray:
        """ROI ì˜ì—­ ì¶”ì¶œ"""
        return screenshot[roi['y']:roi['y']+roi['h'], roi['x']:roi['x']+roi['w']]

# =============================================================================
# 6. ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
# =============================================================================

class PerformanceComparator:
    """ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ì¸ì‹ ê¸°ìˆ  ì„±ëŠ¥ ë¹„êµ"""
    
    def __init__(self):
        self.opencv_matcher = OpenCVTemplateMatcher()
        self.easyocr_detector = EasyOCRDetector()
        self.tesseract_detector = TesseractDetector()
        self.paddleocr_detector = PaddleOCRDetector()
        self.hybrid_detector = HybridTextDetector()
        
    def compare_all_methods(self, iterations: int = 5):
        """ëª¨ë“  ë°©ë²• ì„±ëŠ¥ ë¹„êµ"""
        print(f"\nğŸ¯ í…ìŠ¤íŠ¸ ê¸°ë°˜ UI ìë™í™” ê¸°ìˆ  ë¹„êµ ({iterations}íšŒ í…ŒìŠ¤íŠ¸)")
        print("=" * 70)
        
        results = {
            'OpenCV í…œí”Œë¦¿': [],
            'EasyOCR': [],
            'Tesseract': [],
            'PaddleOCR': [],
            'Hybrid': []
        }
        
        for i in range(iterations):
            print(f"\rğŸ“Š í…ŒìŠ¤íŠ¸ ì§„í–‰: {i+1}/{iterations}", end='', flush=True)
            
            # í™”ë©´ ìº¡ì²˜
            screenshot = self._capture_test_screen()
            
            # 1. OpenCV í…œí”Œë¦¿ ë§¤ì¹­
            found, _, time_taken = self.opencv_matcher.find_button_by_template(screenshot, 'accept')
            results['OpenCV í…œí”Œë¦¿'].append({'found': found, 'time': time_taken * 1000})
            
            # 2. EasyOCR
            found, _, time_taken = self.easyocr_detector.find_button_by_text(screenshot, 'ì ‘ìˆ˜')
            results['EasyOCR'].append({'found': found, 'time': time_taken * 1000})
            
            # 3. Tesseract
            found, _, time_taken = self.tesseract_detector.find_button_by_text(screenshot, 'ì ‘ìˆ˜')
            results['Tesseract'].append({'found': found, 'time': time_taken * 1000})
            
            # 4. PaddleOCR
            found, _, time_taken = self.paddleocr_detector.find_button_by_text(screenshot, 'ì ‘ìˆ˜')
            results['PaddleOCR'].append({'found': found, 'time': time_taken * 1000})
            
            # 5. Hybrid
            found, _, time_taken, _ = self.hybrid_detector.find_button_smart(screenshot, 'ì ‘ìˆ˜', 'accept')
            results['Hybrid'].append({'found': found, 'time': time_taken * 1000})
            
            time.sleep(0.1)
        
        print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n")
        self._print_comparison_results(results)
    
    def _capture_test_screen(self) -> np.ndarray:
        """í…ŒìŠ¤íŠ¸ìš© í™”ë©´ ìº¡ì²˜"""
        with mss.mss() as sct:
            monitor = {"top": 100, "left": 100, "width": 1000, "height": 700}
            screenshot = sct.grab(monitor)
            return np.array(screenshot)[:, :, :3]
    
    def _print_comparison_results(self, results: Dict):
        """ê²°ê³¼ ì¶œë ¥"""
        print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print("=" * 70)
        print(f"{'ë°©ë²•':<15} {'í‰ê· ì†ë„(ms)':<12} {'ì„±ê³µë¥ (%)':<10} {'ì•ˆì •ì„±':<8} {'ì¶”ì²œë„'}")
        print("-" * 70)
        
        recommendations = {
            'OpenCV í…œí”Œë¦¿': 'â­â­',
            'EasyOCR': 'â­â­â­â­â­',
            'Tesseract': 'â­â­â­',
            'PaddleOCR': 'â­â­â­â­',
            'Hybrid': 'â­â­â­â­â­'
        }
        
        for method, data in results.items():
            if data and data[0]['time'] < 9000:  # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•ë§Œ
                avg_time = sum(r['time'] for r in data) / len(data)
                success_rate = sum(1 for r in data if r['found']) / len(data) * 100
                stability = "ë†’ìŒ" if success_rate > 80 else "ë³´í†µ" if success_rate > 50 else "ë‚®ìŒ"
                
                print(f"{method:<15} {avg_time:>8.1f}ms    {success_rate:>6.1f}%    {stability:<8} {recommendations[method]}")
            else:
                print(f"{method:<15} {'ì‚¬ìš©ë¶ˆê°€':<12} {'N/A':<10} {'N/A':<8} {recommendations[method]}")
        
        print("\nğŸ’¡ ì¢…í•© ë¶„ì„:")
        print("ğŸ¥‡ **EasyOCR**: ê°€ì¥ ê· í˜•ì¡íŒ ì„±ëŠ¥, í•œê¸€ ì§€ì› ìš°ìˆ˜")
        print("ğŸ¥ˆ **Hybrid**: ìµœê³  ì„±ëŠ¥ì´ì§€ë§Œ ë³µì¡í•¨")  
        print("ğŸ¥‰ **PaddleOCR**: ë†’ì€ ì •í™•ë„, í•˜ì§€ë§Œ ìš©ëŸ‰ í¼")
        print("ğŸ“‰ **OpenCV**: í…ìŠ¤íŠ¸ UIì—ëŠ” ë¶€ì í•©")
        print("âš¡ **Tesseract**: ë¹ ë¥´ì§€ë§Œ í•œê¸€ ì¸ì‹ë¥  ë‚®ìŒ")
        
        print("\nğŸ¯ **ë°°ë‹¬ì•± ìë™í™” ì¶”ì²œ**:")
        print("1ìˆœìœ„: EasyOCR (ì„¤ì¹˜ ì‰¬ì›€, ì„±ëŠ¥ ì¢‹ìŒ)")
        print("2ìˆœìœ„: Hybrid ë°©ì‹ (ìµœê³  ì„±ëŠ¥, ë³µì¡í•¨)")
        print("3ìˆœìœ„: PaddleOCR (ì •í™•í•˜ì§€ë§Œ ë¬´ê±°ì›€)")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ¯ í…ìŠ¤íŠ¸ ê¸°ë°˜ UI ìë™í™” ê¸°ìˆ  ë¹„êµ")
    print("ë°°ë‹¬ì•± 'ì ‘ìˆ˜', 'ê±°ë¶€' ë²„íŠ¼ ê°™ì€ í…ìŠ¤íŠ¸ UI ìµœì í™”")
    print()
    
    comparator = PerformanceComparator()
    
    try:
        choice = input("í…ŒìŠ¤íŠ¸ íšŸìˆ˜ ì„ íƒ (1=ë¹ ë¥¸í…ŒìŠ¤íŠ¸, 2=í‘œì¤€í…ŒìŠ¤íŠ¸, 3=ì •í™•í•œí…ŒìŠ¤íŠ¸): ").strip()
        iterations = {'1': 3, '2': 5, '3': 10}.get(choice, 5)
        
        comparator.compare_all_methods(iterations)
        
        print("\nğŸš€ ì‹¤ì œ ì ìš© ë°©ë²•:")
        print("1. EasyOCR ì‚¬ìš©: pip install easyocr")
        print("2. ê¸°ì¡´ ImageMatcherë¥¼ TextBasedMatcherë¡œ êµì²´")
        print("3. 'ì ‘ìˆ˜', 'ê±°ë¶€' í…ìŠ¤íŠ¸ë¡œ ì§ì ‘ ë²„íŠ¼ ì°¾ê¸°")
        print("4. í•´ìƒë„ ì™„ì „ ë…ë¦½ì  + 90% ì´ìƒ ì •í™•ë„!")
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨ë¨")

if __name__ == "__main__":
    main()
